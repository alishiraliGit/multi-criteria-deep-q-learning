

Choose a distinguishing exp_name since it is how a PrunedDQN finds previously saved runs.

Run DQN on LunarLander with customized reward weights (the first four values in front of env_rew_weights correspond to intermediate rewards, and the last value corresponds to the final reward):

python cs285/scripts/run_dqn.py \
--exp_name p1 \
--env_name LunarLander-Customizable \
--env_rew_weights a b c d e \
--double_q --seed 1

--------------------
Run DQN on LunarLander with default rewards:

python cs285/scripts/run_dqn.py \
--exp_name p1_default \
--env_name LunarLander-Customizable \
--env_rew_weights 1 1 1 1 1 \
--double_q --seed 1


Run PrunedDQN on LunarLander with default rewards (pruning_file_prefix is the common prefix of previous runs exp_name):

python cs285/scripts/run_dqn.py \
--exp_name p1_pruned_default \
--env_name LunarLander-Customizable \
--env_rew_weights 1 1 1 1 1 \
--pruning_file_prefix p1_LunarLander-Customizable \
--double_q --seed 1

--------------------
Run DQN on LunarLander with sparse rewards:

python cs285/scripts/run_dqn.py \
--exp_name p1_sparse \
--env_name LunarLander-Customizable \
--env_rew_weights 0 0 0 0 1 \
--double_q --seed 1


Run PrunedDQN on LunarLander with sparse rewards (pruning_file_prefix is the common prefix of previous runs exp_name):

python cs285/scripts/run_dqn.py \
--exp_name p1_pruned_sparse \
--env_name LunarLander-Customizable \
--env_rew_weights 0 0 0 0 1 \
--pruning_file_prefix p1_LunarLander-Customizable \
--double_q --seed 1